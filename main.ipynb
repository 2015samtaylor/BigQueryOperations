{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json \n",
    "import pysftp\n",
    "import os\n",
    "import pandas_gbq\n",
    "import pandas as pd\n",
    "from modules.buckets import *\n",
    "from modules.reproducibility import *\n",
    "import logging\n",
    "\n",
    "#Configure loggging\n",
    "logging.basicConfig(filename='BigQuery.log', level=logging.INFO,\n",
    "                   format='%(asctime)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S')\n",
    "logging.info('\\n\\n-------------New Big Query Logging Instance')\n",
    "\n",
    "# Set the GOOGLE_APPLICATION_CREDENTIALS environment variable in order to interact, import the SFTP password from the same file\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = 'powerschool-420113-db919282054b.json'\n",
    "with open('powerschool-420113-db919282054b.json') as json_file:\n",
    "    j = json.load(json_file) \n",
    "    sftp_pass = j['sftp_password']\n",
    "    \n",
    "# ----------------------------------------------------------\n",
    "#Need to make this portion to where it assesses all files in the dir recursively. \n",
    "def main(SFTP_folder_name):\n",
    "\n",
    "    SFTP_folder_name  = initial_schema_check(SFTP_folder_name)\n",
    "    print(SFTP_folder_name)\n",
    "\n",
    "    instance = Create(\n",
    "                project_id='powerschool-420113',\n",
    "                location = 'us-south1',\n",
    "                bucket=f'{SFTP_folder_name}bucket-iotaschools-1',\n",
    "                local_dir = f'SFTP_folders\\\\{SFTP_folder_name}',\n",
    "                db = SFTP_folder_name,\n",
    "                append_or_replace='replace',\n",
    "                )\n",
    "\n",
    "    SFTP_conn(sftp_pass, SFTP_folder_name) #Replicate SFTP folder onto local dir\n",
    "    instance.process()#Replicate local dir into Buckets, pass dir filesinto Bucket & finally into Big Query tables\n",
    "\n",
    "main('EIS')\n",
    "main('powerschool')\n",
    "\n",
    "#When running two at one time it does not get all files from the SFTP initially. \n",
    "#Therefore connection open & closes. \n",
    "\n",
    "#Took 4 minutes to get the powerschool folder downloaded. \n",
    "#Less than a minute to send files to Bucket, and Big Query\n",
    "\n",
    "#EIS 5 min mark\n",
    "#Issue with downloading the EIS_prior_schools.csv\n",
    "#Could be a way with how I am opening and closing the connection to where it hangs on it. \n",
    "#Went for over an hour. \n",
    "\n",
    "#Going to either need to download all files at one time, or re-frame the conection. \n",
    "#Look into connection pooling\n",
    "\n",
    "#The file immediately ends up on there, but that function simply hangs. \n",
    "\n",
    "#Next one started at 4:40\n",
    "#Immediately got downloaded in the first 12 seconds. \n",
    "#Finished in 6 mins\n",
    "\n",
    "#7 mins PS started, immediately downloaded files. Then hangs\n",
    "#Finished in 13 minutes\n",
    "#Never closed the connection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
